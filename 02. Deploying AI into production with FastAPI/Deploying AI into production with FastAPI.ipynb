{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2843d105-0a25-4c9f-9b55-4c9677e072ad",
   "metadata": {},
   "source": [
    "# Deploying AI into production with FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed57a5-f8e8-4c94-b6f9-b9f3190e4e6d",
   "metadata": {},
   "source": [
    "## Chapter 1 - Introducion to FastAPI for Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da86eb5-b9a1-4f6d-8dac-4e3113a094f9",
   "metadata": {},
   "source": [
    "### Section 1.1 - GET and POST requests for AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f1fc9-dd5c-4d65-a6bd-6a1237e427a1",
   "metadata": {},
   "source": [
    "#### GET endpoint for model information\n",
    "\n",
    "You're part of a machine learning team that has developed several machine learning models, each designed for different tasks such as sentiment analysis, product categorization, and customer churn prediction. You're working on deploying these models, and you need to create an endpoint that provides basic information about each model.\n",
    "\n",
    "Your task is to implement a GET endpoint at route `/model-info/{model_id}` that retrieves and returns this essential model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49366a73-f3f2-46e0-83cd-f098c5fd40ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from fastapi import FastAPI, HTTPException\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Add model_id as a path parameter in the route\n",
    "@app.get(\"/model-info/{model_id}\")\n",
    "# Pass on the model id as an argument\n",
    "async def get_model_info(model_id: int):\n",
    "    # Check if the passed model id is 0\n",
    "    if model_id == 0:\n",
    "      \t# Raise the right status code for not found\n",
    "        raise HTTPException(status_code=404, detail=\"Model not found\")\n",
    "    model_info = get_model_details(id)  \n",
    "    # Return the model id and info in the dict\n",
    "    return {\"model_id\": model_id, \"model_name\": model_info}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97aab6-7399-4def-a802-0d1e8824fcdd",
   "metadata": {},
   "source": [
    "#### POST endpoint for model registration\n",
    "\n",
    "While the GET endpoint you created earlier allows users to retrieve information about existing models, you now need a way for authorized team members to register new models or update information about existing ones.\n",
    "\n",
    "You need to create a POST endpoint that allows team members to register new models or update existing ones. This endpoint will store model information on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c85e3df6-5259-4470-a287-de2fb5530746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from pydantic import BaseModel\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model_db = {}\n",
    "\n",
    "class ModelInfo(BaseModel):\n",
    "    model_id: int\n",
    "    model_name: str\n",
    "    description: str\n",
    "\n",
    "# Specify the status code for successful POST request\n",
    "@app.post(\"/register-model\", status_code=201)\n",
    "# Pass the model info from the request as function parameter \n",
    "def register_model(model_info: ModelInfo):\n",
    "    # Add new model's information dictionary to the model database\n",
    "    model_db[model_info.model_id] = model_info.model_dump()\n",
    "    # Return model info dictionary corresponding to model along with success status code\n",
    "    return {\"message\": \"Model registered successfully\", \"model\": model_info}, 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7714a249-fe00-4dde-bad4-d5ebf037dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message': 'Model registered successfully', 'model': {'model_id': 1, 'model_name': 'cnn', 'description': 'convolutional nn'}}, 201]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    \"model_id\":1, \n",
    "    \"model_name\": \"cnn\", \n",
    "    \"description\": \"convolutional nn\"}\n",
    "\n",
    "url = \"http://localhost:8000/register-model\"\n",
    "headers = {\"Content_Type\": \"Application-json\"}\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c78b6-a13a-404e-a573-5201ec5c31ea",
   "metadata": {},
   "source": [
    "### Section 1.2 - FastAPI prediction with a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40ee3fda-738c-4545-a98f-0421bf2a24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"SIH/palmer-penguins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f30acb74-0d6b-410a-9e87-1dcdb5897988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN    None  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c177333-a1a9-40e2-9bd3-3f25bff45c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.98181818 1.         1.         0.98148148 1.        ]\n",
      "Mean CV accuracy: 0.9926599326599327\n",
      "Accuracy: 0.9855072463768116\n",
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "features = ['species', 'bill_length_mm', 'bill_depth_mm',\n",
    "       'flipper_length_mm', 'body_mass_g']\n",
    "\n",
    "df_dataset = df[features]\n",
    "df_dataset = df_dataset.dropna()\n",
    "X = df_dataset.drop(\"species\", axis=1)\n",
    "y = df_dataset[\"species\"]\n",
    "\n",
    "# 1. Split first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Perform cross-validation only on the training set\n",
    "cv_scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "\n",
    "# 3. See accuracy on each fold\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# 4. Fit on train on full dataset\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predict and evaluate on the test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save the pipeline (includes scaler + model)\n",
    "joblib.dump(pipe, \"penguin_classifier.pkl\")\n",
    "\n",
    "# Load the saved pipeline\n",
    "model = joblib.load(\"penguin_classifier.pkl\")\n",
    "print(type(model))\n",
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72669f6d-740c-4a03-8f79-aba10b038ee4",
   "metadata": {},
   "source": [
    "#### Load the pre-trained model\n",
    "\n",
    "You're a data scientist at an animal conservation company. You've been given a pre-trained machine learning model that predicts penguin species.\n",
    "\n",
    "Your task is to load this model so it can be used in an API. The model has been saved using `joblib`.\n",
    "\n",
    "A pre-trained ML model is stored in the pickle file: `penguin_classifier.pkl`\n",
    "\n",
    "Write a script to load the pickle file as a model. Test your script by running `python3 solution.py` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "77789f78-3e7d-4afc-baad-ebe1576f37b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model type: <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module\n",
    "import joblib\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = joblib.load('penguin_classifier.pkl')\n",
    "\n",
    "# Print the type of the loaded model\n",
    "print(f\"Loaded model type: {type(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870e446-3092-4d5a-9595-9c28438637c7",
   "metadata": {},
   "source": [
    "#### Create the prediction endpoint\n",
    "\n",
    "In this exercise, you'll create a prediction endpoint that uses a pre-trained model to estimate diabetes progression.\n",
    "\n",
    "The model has been trained on a dataset which has three features age, bmi and blood_pressure. It then predicts the diabetes progression score. Using these inputs, it predicts a diabetes progression score, which helps assess how the condition may develop over time.\n",
    "\n",
    "You'll use FastAPI to create a POST endpoint that accepts patient data and returns a prediction of diabetes progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6cf78330-7de2-44cd-a527-b5d498c67896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm',\n",
       "       'body_mass_g'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "70bc79d1-0422-4673-aec0-01e2cb551365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bill_length_mm': 39.1, 'bill_depth_mm': 18.7, 'flipper_length_mm': 181.0, 'body_mass_g': 3750.0}\n",
      "   bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
      "0            39.1           18.7              181.0       3750.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predicted_progression': 'Adelie'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "\n",
    "class PengiunFeatures(BaseModel):\n",
    "    bill_length_mm: float\n",
    "    bill_depth_mm: float\n",
    "    flipper_length_mm: float\n",
    "    body_mass_g: float\n",
    "    \n",
    "# Create FastAPI instance\n",
    "app = FastAPI()\n",
    "\n",
    "# Create a POST request endpoint at the route \"/predict\"\n",
    "def predict_progression(features: PengiunFeatures):\n",
    "    input_data = pd.DataFrame([pengiun.model_dump()])\n",
    "    \n",
    "    print(input_data)\n",
    "    # Use the predict method to make a prediction\n",
    "    prediction = model.predict(input_data)\n",
    "    return {\"predicted_progression\": prediction[0]}\n",
    "\n",
    "pengiun = PengiunFeatures(bill_length_mm=39.1,\n",
    "                          bill_depth_mm=18.7,\n",
    "                          flipper_length_mm=181.0,\n",
    "                          body_mass_g=3750.0)\n",
    "\n",
    "print(pengiun.model_dump())\n",
    "predict_progression(pengiun)\n",
    "\n",
    "# # Create a POST request endpoint at the route \"/predict\"\n",
    "# @app.post(\"/predict\")\n",
    "# async def predict_progression(features: PengiunFeatures):\n",
    "#     input_data = [[\n",
    "#         features.age,\n",
    "#         features.bmi,\n",
    "#         features.blood_pressure\n",
    "#     ]]\n",
    "    \n",
    "#     # Use the predict method to make a prediction\n",
    "#     prediction = model.predict(input_data)\n",
    "#     return {\"predicted_progression\": float(prediction[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0886cc53-15db-4d0a-8ae2-db29ee129cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = joblib.load('penguin_classifier.pkl')\n",
    "\n",
    "# Print the type of the loaded model\n",
    "print(f\"Loaded model type: {type(model)}\")\n",
    "class PengiunFeatures(BaseModel):\n",
    "    bill_length_mm: float\n",
    "    bill_depth_mm: float\n",
    "    flipper_length_mm: float\n",
    "    body_mass_g: float\n",
    "    \n",
    "# Create FastAPI instance\n",
    "app = FastAPI()\n",
    "\n",
    "# # Create a POST request endpoint at the route \"/predict\"\n",
    "@app.post(\"/predict\")\n",
    "async def predict_progression(features: PengiunFeatures):\n",
    "    input_data = pd.DataFrame([features.model_dump()])\n",
    "    \n",
    "    prediction = model.predict(input_data)\n",
    "    return {\"predicted_progression\": prediction[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "89b1e539-d6e1-4623-b65a-122f089acde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_progression': 'Adelie'}\n"
     ]
    }
   ],
   "source": [
    "pengiun = PengiunFeatures(bill_length_mm=39.1,\n",
    "                          bill_depth_mm=18.7,\n",
    "                          flipper_length_mm=181.0,\n",
    "                          body_mass_g=3750.0)\n",
    "\n",
    "url = \"http://localhost:8000/predict\"\n",
    "data = pengiun.model_dump()\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b096eefb-5e71-4963-a5e5-b5a8100b8bcb",
   "metadata": {},
   "source": [
    "#### Running the FastAPI app\n",
    "\n",
    "Your FastAPI app has been saved in a Python file called `main.py`. You would like to run the app from a Python script using uvicorn.\n",
    "\n",
    "To serve your FastAPI app directly via the Python script in `solution.py`, you need to finish adding the code block that sets up the host and port of the server where the API will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6926a360-cc7a-4b75-ba93-5196ab2572ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing solution.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile solution.py\n",
    "# Import the server module\n",
    "import uvicorn\n",
    "from main import app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Start the uvicorn server\n",
    "    uvicorn.run(\n",
    "\t  app, \n",
    "      # Configure the host\n",
    "      host=\"0.0.0.0\",\n",
    "      # Configure the port\n",
    "      port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "100785d6-0b82-491f-ba2b-3ec4b8880d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model type: <class 'sklearn.pipeline.Pipeline'>\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m475095\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8080\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:40836 - \"\u001b[1mGET /hello HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:40852 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:40852 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:40856 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:40848 - \"\u001b[1mGET /docs HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:40848 - \"\u001b[1mGET /openapi.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
      "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m475095\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "!python3 solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4e927-ed17-47d6-b0c0-2cfeb0d81963",
   "metadata": {},
   "source": [
    "now post to the server on port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5d21845a-e1cf-4655-a4d0-904facf652c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_progression': 'Adelie'}\n"
     ]
    }
   ],
   "source": [
    "pengiun = PengiunFeatures(bill_length_mm=39.1,\n",
    "                          bill_depth_mm=18.7,\n",
    "                          flipper_length_mm=181.0,\n",
    "                          body_mass_g=3750.0)\n",
    "\n",
    "url = \"http://localhost:8080/predict\"\n",
    "data = pengiun.model_dump()\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4013476-c989-48ed-b514-856215de52dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
