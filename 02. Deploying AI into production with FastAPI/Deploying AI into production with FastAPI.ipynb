{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2843d105-0a25-4c9f-9b55-4c9677e072ad",
   "metadata": {},
   "source": [
    "# Deploying AI into production with FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed57a5-f8e8-4c94-b6f9-b9f3190e4e6d",
   "metadata": {},
   "source": [
    "## Chapter 1 - Introducion to FastAPI for Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da86eb5-b9a1-4f6d-8dac-4e3113a094f9",
   "metadata": {},
   "source": [
    "### Section 1.1 - GET and POST requests for AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f1fc9-dd5c-4d65-a6bd-6a1237e427a1",
   "metadata": {},
   "source": [
    "#### GET endpoint for model information\n",
    "\n",
    "You're part of a machine learning team that has developed several machine learning models, each designed for different tasks such as sentiment analysis, product categorization, and customer churn prediction. You're working on deploying these models, and you need to create an endpoint that provides basic information about each model.\n",
    "\n",
    "Your task is to implement a GET endpoint at route `/model-info/{model_id}` that retrieves and returns this essential model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49366a73-f3f2-46e0-83cd-f098c5fd40ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from fastapi import FastAPI, HTTPException\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Add model_id as a path parameter in the route\n",
    "@app.get(\"/model-info/{model_id}\")\n",
    "# Pass on the model id as an argument\n",
    "async def get_model_info(model_id: int):\n",
    "    # Check if the passed model id is 0\n",
    "    if model_id == 0:\n",
    "      \t# Raise the right status code for not found\n",
    "        raise HTTPException(status_code=404, detail=\"Model not found\")\n",
    "    model_info = get_model_details(id)  \n",
    "    # Return the model id and info in the dict\n",
    "    return {\"model_id\": model_id, \"model_name\": model_info}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97aab6-7399-4def-a802-0d1e8824fcdd",
   "metadata": {},
   "source": [
    "#### POST endpoint for model registration\n",
    "\n",
    "While the GET endpoint you created earlier allows users to retrieve information about existing models, you now need a way for authorized team members to register new models or update information about existing ones.\n",
    "\n",
    "You need to create a POST endpoint that allows team members to register new models or update existing ones. This endpoint will store model information on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c85e3df6-5259-4470-a287-de2fb5530746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from pydantic import BaseModel\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model_db = {}\n",
    "\n",
    "class ModelInfo(BaseModel):\n",
    "    model_id: int\n",
    "    model_name: str\n",
    "    description: str\n",
    "\n",
    "# Specify the status code for successful POST request\n",
    "@app.post(\"/register-model\", status_code=201)\n",
    "# Pass the model info from the request as function parameter \n",
    "def register_model(model_info: ModelInfo):\n",
    "    # Add new model's information dictionary to the model database\n",
    "    model_db[model_info.model_id] = model_info.model_dump()\n",
    "    # Return model info dictionary corresponding to model along with success status code\n",
    "    return {\"message\": \"Model registered successfully\", \"model\": model_info}, 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7714a249-fe00-4dde-bad4-d5ebf037dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message': 'Model registered successfully', 'model': {'model_id': 1, 'model_name': 'cnn', 'description': 'convolutional nn'}}, 201]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    \"model_id\":1, \n",
    "    \"model_name\": \"cnn\", \n",
    "    \"description\": \"convolutional nn\"}\n",
    "\n",
    "url = \"http://localhost:8000/register-model\"\n",
    "headers = {\"Content_Type\": \"Application-json\"}\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c78b6-a13a-404e-a573-5201ec5c31ea",
   "metadata": {},
   "source": [
    "### Section 1.2 - FastAPI prediction with a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302abcba-a153-4fe6-ba9a-6d087fb64eec",
   "metadata": {},
   "source": [
    "#### Preperation\n",
    "\n",
    "The model from the exercises does not work. So hwere we quickly trains and save our own model that can be used for the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40ee3fda-738c-4545-a98f-0421bf2a24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"SIH/palmer-penguins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f30acb74-0d6b-410a-9e87-1dcdb5897988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN    None  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6afbf68-a3bb-41c9-9bcc-3b3c11c89ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: [0.98181818 1.         1.         0.98148148 1.        ]\n",
      "Mean CV accuracy: 0.9926599326599327\n",
      "Test set accuracy: 0.9855072463768116\n",
      "Loaded model type: <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Only include numerical features + target\n",
    "features = ['species', 'bill_length_mm', 'bill_depth_mm',\n",
    "            'flipper_length_mm', 'body_mass_g']\n",
    "\n",
    "# 0. Prepare the dataset\n",
    "df_dataset = df[features].dropna()\n",
    "X = df_dataset.drop(\"species\", axis=1)\n",
    "y = df_dataset[\"species\"]\n",
    "\n",
    "# 1. Split first\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Define pipeline (scaler + classifier)\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "# 3. Perform cross-validation only on the training set\n",
    "cv_scores = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "\n",
    "# 4. Report CV accuracy\n",
    "print(\"Cross-validation accuracy scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# 5. Fit the pipeline on the full training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate on the test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Test set accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# 7. Save the pipeline (includes scaler + model)\n",
    "joblib.dump(pipe, \"penguin_classifier.pkl\")\n",
    "\n",
    "# 8. Load the pipeline\n",
    "model = joblib.load(\"penguin_classifier.pkl\")\n",
    "print(\"Loaded model type:\", type(model))\n",
    "\n",
    "# 9. Use the loaded model for prediction\n",
    "# (Optional — uncomment to test)\n",
    "# y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72669f6d-740c-4a03-8f79-aba10b038ee4",
   "metadata": {},
   "source": [
    "#### Load the pre-trained model\n",
    "\n",
    "You're a data scientist at an animal conservation company. You've been given a pre-trained machine learning model that predicts penguin species.\n",
    "\n",
    "Your task is to load this model so it can be used in an API. The model has been saved using `joblib`.\n",
    "\n",
    "A pre-trained ML model is stored in the pickle file: `penguin_classifier.pkl`\n",
    "\n",
    "Write a script to load the pickle file as a model. Test your script by running `python3 solution.py` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77789f78-3e7d-4afc-baad-ebe1576f37b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model type: <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module\n",
    "import joblib\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = joblib.load('penguin_classifier.pkl')\n",
    "\n",
    "# Print the type of the loaded model\n",
    "print(f\"Loaded model type: {type(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870e446-3092-4d5a-9595-9c28438637c7",
   "metadata": {},
   "source": [
    "#### Create the prediction endpoint\n",
    "\n",
    "In this exercise, you'll create a prediction endpoint that uses a pre-trained model to estimate diabetes progression.\n",
    "\n",
    "The model has been trained on a dataset which has three features age, bmi and blood_pressure. It then predicts the diabetes progression score. Using these inputs, it predicts a diabetes progression score, which helps assess how the condition may develop over time.\n",
    "\n",
    "You'll use FastAPI to create a POST endpoint that accepts patient data and returns a prediction of diabetes progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7222cd36-5aa8-4bd1-a522-2ca80129a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = joblib.load('penguin_classifier.pkl')\n",
    "\n",
    "# Print the type of the loaded model\n",
    "print(f\"Loaded model type: {type(model)}\")\n",
    "class PengiunFeatures(BaseModel):\n",
    "    bill_length_mm: float\n",
    "    bill_depth_mm: float\n",
    "    flipper_length_mm: float\n",
    "    body_mass_g: float\n",
    "    \n",
    "# Create FastAPI instance\n",
    "app = FastAPI()\n",
    "\n",
    "# # Create a POST request endpoint at the route \"/predict\"\n",
    "@app.post(\"/predict\")\n",
    "async def predict_progression(features: PengiunFeatures):\n",
    "    input_data = pd.DataFrame([features.model_dump()])\n",
    "    \n",
    "    prediction = model.predict(input_data)\n",
    "    return {\"predicted_progression\": prediction[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10fe37eb-8b31-4c08-8f5e-a362e866a924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_progression': 'Adelie'}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "import requests\n",
    "\n",
    "class PengiunFeatures(BaseModel):\n",
    "    bill_length_mm: float\n",
    "    bill_depth_mm: float\n",
    "    flipper_length_mm: float\n",
    "    body_mass_g: float\n",
    "\n",
    "\n",
    "pengiun = PengiunFeatures(bill_length_mm=39.1,\n",
    "                          bill_depth_mm=18.7,\n",
    "                          flipper_length_mm=181.0,\n",
    "                          body_mass_g=3750.0)\n",
    "\n",
    "url = \"http://localhost:8000/predict\"\n",
    "data = pengiun.model_dump()\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b096eefb-5e71-4963-a5e5-b5a8100b8bcb",
   "metadata": {},
   "source": [
    "#### Running the FastAPI app\n",
    "\n",
    "Your FastAPI app has been saved in a Python file called `main.py`. You would like to run the app from a Python script using uvicorn.\n",
    "\n",
    "To serve your FastAPI app directly via the Python script in `solution.py`, you need to finish adding the code block that sets up the host and port of the server where the API will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6926a360-cc7a-4b75-ba93-5196ab2572ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting solution.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile solution.py\n",
    "# Import the server module\n",
    "import uvicorn\n",
    "from main import app\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Start the uvicorn server\n",
    "    uvicorn.run(\n",
    "\t  app, \n",
    "      # Configure the host\n",
    "      host=\"0.0.0.0\",\n",
    "      # Configure the port\n",
    "      port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb1087-0dd8-4f32-85e5-3ab9e7ca371b",
   "metadata": {},
   "source": [
    "with the snippet below we can start the server using python. It is best to do this in a terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100785d6-0b82-491f-ba2b-3ec4b8880d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4e927-ed17-47d6-b0c0-2cfeb0d81963",
   "metadata": {},
   "source": [
    "now post to the server on port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d21845a-e1cf-4655-a4d0-904facf652c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_progression': 'Adelie'}\n"
     ]
    }
   ],
   "source": [
    "pengiun = PengiunFeatures(bill_length_mm=39.1,\n",
    "                          bill_depth_mm=18.7,\n",
    "                          flipper_length_mm=181.0,\n",
    "                          body_mass_g=3750.0)\n",
    "\n",
    "url = \"http://localhost:8080/predict\"\n",
    "data = pengiun.model_dump()\n",
    "response = requests.post(url, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433b739-3564-48d5-8249-6006c347bd71",
   "metadata": {},
   "source": [
    "### Section 1.3 - Create a PYdantic model for ML input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86012f62-44b8-4d32-adc1-b1eb07ae9e17",
   "metadata": {},
   "source": [
    "#### Create a Pydantic model for ML input\n",
    "\n",
    "You're developing a FastAPI application to deploy a machine learning model that predicts the quality score of coffee based on attributes including aroma, flavor, and altitude.\n",
    "\n",
    "The first step is to create a Pydantic model to validate the input request data for your ML model and ensure that only valid data flows through the model for successful model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "184b18be-ca8a-4379-aed3-7054407b6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the base class from pydantic\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CoffeeQualityInput(BaseModel):\n",
    "    # Use apt data type for each attribute of coffee quality\n",
    "    aroma: float  \n",
    "    flavor: float  \n",
    "    altitude: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40da73c-caef-43a0-ba6a-add1198ca38f",
   "metadata": {},
   "source": [
    "#### Validate request and response for ML prediction\n",
    "\n",
    "Building on your work as a data scientist at the coffee company, you now need to create a FastAPI endpoint that validates input request using `CoffeeQualityInput` data validation model and a `QualityPrediction` for response validation.\n",
    "\n",
    "This endpoint will accept coffee data and return a quality prediction along with the confidence score.\n",
    "\n",
    "The model is already loaded into a function called `predict_quality` for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c306f479-068d-4a42-8ff3-51c6193034d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoffeeQualityInput(BaseModel):\n",
    "    aroma: float\n",
    "    flavor: float\n",
    "    altitude: int\n",
    "    \n",
    "class QualityPrediction(BaseModel):\n",
    "    quality_score: float \n",
    "    confidence: float\n",
    "\n",
    "# Specify the data model to validate response\n",
    "@app.post(\"/predict\", response_model=QualityPrediction) \n",
    "# Specify the data model to validate input request\n",
    "def predict(coffee_data: CoffeeQualityInput):\n",
    "    prediction = predict_quality(coffee_data)\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22377c-6ad9-490d-a20b-1e12b3fd977f",
   "metadata": {},
   "source": [
    "## Chapter 2 - Integrating AI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846493b9-0f2e-429f-ac64-ab8bfb79c770",
   "metadata": {},
   "source": [
    "#### Handle textual request data\n",
    "\n",
    "Another requirement in the content moderation system is to take into account user comments' sentiment. The system needs to identify specific problematic phrases to help moderators review potentially inappropriate content.\n",
    "\n",
    "You'll create an endpoint that analyzes text coming from users and extracts standardized moderation flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3c1f161-7b16-44ea-95b0-25a2281a9f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/analyze_comment\")\n",
    "def analyze_comment(text: str):\n",
    "    problem_keywords = [\"spam\", \"hate\", \"offensive\", \"abuse\"]\n",
    "    \n",
    "    # Convert the input text to lowercase\n",
    "    text_lower = text.lower()\n",
    "    # Extract matching flags using list comprehension\n",
    "    found_issues = [keyword for keyword in problem_keywords if keyword in text_lower]\n",
    "    # Return the dictionary with required keys\n",
    "    return {\n",
    "        \"issues\": found_issues,\n",
    "        \"issue_count\": len(found_issues),\n",
    "        \"original_text\": text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d5310d3-52f7-42f1-8e2e-49fad6228d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'issues': ['spam', 'hate'], 'issue_count': 2, 'original_text': 'This is a spam with spam which I hate and abusive message'}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    \"http://localhost:8000/analyze_comment?text=This is a spam with spam which I hate and abusive message\"\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147fe48-93b4-4b41-a364-6bf8e6c7aa3d",
   "metadata": {},
   "source": [
    "#### Handle numerical request data\n",
    "\n",
    "You're building a content moderation system. The system needs to calculate a trust score for each user comment based on numerical features - `length`, `user_reputation`, and `report_count`. You'll create an endpoint that processes these features to make them compatible for the moderation model.\n",
    "\n",
    "Note that the ML model and `CommentMetrics Pydantic model with `length`(int), `user_reputation`(int) and `report_count`(int) are already created and loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce1f4f3b-5c61-49d6-8f95-4f35f42a7151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scorer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scorer.py\n",
    "import numpy as np\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CommentMetrics(BaseModel):\n",
    "    length: int\n",
    "    user_reputation: int\n",
    "    report_count: int\n",
    "\n",
    "class CommentScorer:\n",
    "    def predict(self, features: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Predict trust score based on comment metrics\n",
    "        features: [[length, user_reputation, report_count]]\n",
    "        \"\"\"\n",
    "        # Unpack features\n",
    "        length, reputation, reports = features[0]\n",
    "        \n",
    "        # Calculate trust score\n",
    "        score = (0.3 * (length/500) +        # Normalize length\n",
    "                 0.5 * (reputation/100) +    # Normalize reputation\n",
    "                 -0.2 * reports)             # Reports reduce score\n",
    "        \n",
    "        return float(max(min(score * 100, 100), 0))  # Scale to 0-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "294fd071-3eca-490c-9f89-265e9c50066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import numpy as np\n",
    "from scorer import CommentMetrics, CommentScorer\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "model = CommentScorer()\n",
    "\n",
    "@app.post(\"/predict_trust\")\n",
    "def predict_trust(comment: CommentMetrics):\n",
    "    # Convert input and extract comment metrics\n",
    "    features = np.array([[\n",
    "        comment.length,\n",
    "        comment.user_reputation,\n",
    "        comment.report_count\n",
    "    ]])\n",
    "    # Get prediction from model \n",
    "    score = model.predict(features)\n",
    "    return {\n",
    "        \"trust_score\": round(score, 2),\n",
    "        \"comment_metrics\": comment.dict()\n",
    "    }\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8080)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8fc44ca-d68f-4902-992b-ef81ed32ffde",
   "metadata": {},
   "source": [
    "curl -X POST \"http://localhost:8080/predict_trust\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\n",
    "           \"length\": 150,\n",
    "           \"user_reputation\": 100,\n",
    "           \"report_count\": 0\n",
    "         }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e431c89-cc86-4f28-ba41-addd24825300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trust_score': 59.0, 'comment_metrics': {'length': 150, 'user_reputation': 100, 'report_count': 0}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8080/predict_trust\"\n",
    "data = {\n",
    "    \"length\": 150,\n",
    "    \"user_reputation\": 100,\n",
    "    \"report_count\": 0}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c842068-ab13-4ba8-991d-4ef10813e102",
   "metadata": {},
   "source": [
    "### Section 2.2 - Input validation in PastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24333293-1271-4ecd-a439-877f41a7d3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71195c-5fe4-45aa-9ed4-e916ee5d95ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
